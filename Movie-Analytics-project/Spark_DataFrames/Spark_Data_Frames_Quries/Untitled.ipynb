{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d3cefbe",
   "metadata": {},
   "source": [
    "# Spark Data Frames\n",
    "\n",
    "1.Prepare Movies data: Extracting the Year and Genre from the Text\n",
    "2.Prepare Users data: Loading a double delimited csv file\n",
    "3.Prepare Ratings data: Programmatically specifying a schema for the data frame\n",
    "4.Import Data from URL: Scala\n",
    "5.Save table without defining DDL in Hive\n",
    "6.Broadcast Variable example\n",
    "7.Accumulator example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0692a35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/jhansiboda/anaconda3/lib/python3.10/site-packages (3.4.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /Users/jhansiboda/anaconda3/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4e87938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jhansiboda/Desktop/MovieAnalytics/Movie-Analytics-project/MovieLens Dataset/\n",
      "DataFrame[_c0: int, _c1: string, _c2: string]\n",
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      "\n",
      "+---+--------------------+--------------------+\n",
      "|_c0|                 _c1|                 _c2|\n",
      "+---+--------------------+--------------------+\n",
      "|  1|    Toy Story (1995)|Animation|Childre...|\n",
      "|  2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|  3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|  4|Waiting to Exhale...|        Comedy|Drama|\n",
      "|  5|Father of the Bri...|              Comedy|\n",
      "|  6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|  7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|  8| Tom and Huck (1995)|Adventure|Children's|\n",
      "|  9| Sudden Death (1995)|              Action|\n",
      "| 10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "+---+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import substring, col\n",
    "home_dir = \"/Users/jhansiboda/Desktop/MovieAnalytics/Movie-Analytics-project/MovieLens Dataset/\"\n",
    "print(home_dir)\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df_movies = spark.read.option(\"header\", \"False\").option(\"delimiter\",\"::\").option(\"inferSchema\",\"true\").csv(home_dir + \"movies.csv\")\n",
    "df_ratings = spark.read.option(\"header\", \"False\").option(\"delimiter\",\"::\").option(\"inferSchema\",\"true\").csv(home_dir + \"ratings.csv\")\n",
    "df_users = spark.read.option(\"header\", \"False\").option(\"delimiter\",\"::\").option(\"inferSchema\",\"true\").csv(home_dir + \"users.csv\")\n",
    "\n",
    "print(df_movies)\n",
    "df_movies.printSchema()\n",
    "df_movies.dtypes\n",
    "df_movies.show(10)\n",
    "df_movies.count()\n",
    "column_names = [\"movie_id\",\"title\",\"genres\"]\n",
    "df_movie = df_movies.toDF(*column_names)\n",
    "\n",
    "# Create an accumulator for counting\n",
    "count_accumulator = spark.sparkContext.accumulator(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0face416",
   "metadata": {},
   "source": [
    "# 1.Prepare Movies data: Extracting the Year and Genre from the Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a00b3ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|movie_id|               title|              genres|\n",
      "+--------+--------------------+--------------------+\n",
      "|       1|    Toy Story (1995)|Animation|Childre...|\n",
      "|       2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|       3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|       4|Waiting to Exhale...|        Comedy|Drama|\n",
      "|       5|Father of the Bri...|              Comedy|\n",
      "|       6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|       7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|       8| Tom and Huck (1995)|Adventure|Children's|\n",
      "|       9| Sudden Death (1995)|              Action|\n",
      "|      10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|      11|American Presiden...|Comedy|Drama|Romance|\n",
      "|      12|Dracula: Dead and...|       Comedy|Horror|\n",
      "|      13|        Balto (1995)|Animation|Children's|\n",
      "|      14|        Nixon (1995)|               Drama|\n",
      "|      15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|      16|       Casino (1995)|      Drama|Thriller|\n",
      "|      17|Sense and Sensibi...|       Drama|Romance|\n",
      "|      18|   Four Rooms (1995)|            Thriller|\n",
      "|      19|Ace Ventura: When...|              Comedy|\n",
      "|      20|  Money Train (1995)|              Action|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movie.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fba1758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- genres: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n",
      "+--------------------+----+\n",
      "|              genres|year|\n",
      "+--------------------+----+\n",
      "|Animation|Childre...|1995|\n",
      "|Adventure|Childre...|1995|\n",
      "|      Comedy|Romance|1995|\n",
      "|        Comedy|Drama|1995|\n",
      "|              Comedy|1995|\n",
      "|Action|Crime|Thri...|1995|\n",
      "|      Comedy|Romance|1995|\n",
      "|Adventure|Children's|1995|\n",
      "|              Action|1995|\n",
      "|Action|Adventure|...|1995|\n",
      "|Comedy|Drama|Romance|1995|\n",
      "|       Comedy|Horror|1995|\n",
      "|Animation|Children's|1995|\n",
      "|               Drama|1995|\n",
      "|Action|Adventure|...|1995|\n",
      "|      Drama|Thriller|1995|\n",
      "|       Drama|Romance|1995|\n",
      "|            Thriller|1995|\n",
      "|              Comedy|1995|\n",
      "|              Action|1995|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, min, max, sum, substring\n",
    "\n",
    "df1 = df_movie.withColumn('year', substring('title', -5, 4).cast('int')).select(col('genres'), col('year'))\n",
    "df1.printSchema()\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf92669",
   "metadata": {},
   "source": [
    "# 2.Prepare Users data: Loading a double delimited csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ff7b142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---+----------+--------+\n",
      "|user_id|gender|age|occupation|zip_code|\n",
      "+-------+------+---+----------+--------+\n",
      "|      1|     F|  1|        10|   48067|\n",
      "|      2|     M| 56|        16|   70072|\n",
      "|      3|     M| 25|        15|   55117|\n",
      "|      4|     M| 45|         7|   02460|\n",
      "|      5|     M| 25|        20|   55455|\n",
      "+-------+------+---+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_names = [\"user_id\", \"gender\", \"age\", \"occupation\", \"zip_code\"]\n",
    "df_user = df_users.toDF(*column_names)\n",
    "df_user.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dac840",
   "metadata": {},
   "source": [
    "# 3.Prepare Ratings data: Programmatically specifying a schema for the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "358d3676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+---------+\n",
      "|user_id|movie_id|rating|timestamp|\n",
      "+-------+--------+------+---------+\n",
      "|      1|    1193|   5.0|978300760|\n",
      "|      1|     661|   3.0|978302109|\n",
      "|      1|     914|   3.0|978301968|\n",
      "|      1|    3408|   4.0|978300275|\n",
      "|      1|    2355|   5.0|978824291|\n",
      "|      1|    1197|   3.0|978302268|\n",
      "|      1|    1287|   5.0|978302039|\n",
      "|      1|    2804|   5.0|978300719|\n",
      "|      1|     594|   4.0|978302268|\n",
      "|      1|     919|   4.0|978301368|\n",
      "|      1|     595|   5.0|978824268|\n",
      "|      1|     938|   4.0|978301752|\n",
      "|      1|    2398|   4.0|978302281|\n",
      "|      1|    2918|   4.0|978302124|\n",
      "|      1|    1035|   5.0|978301753|\n",
      "|      1|    2791|   4.0|978302188|\n",
      "|      1|    2687|   3.0|978824268|\n",
      "|      1|    2018|   4.0|978301777|\n",
      "|      1|    3105|   5.0|978301713|\n",
      "|      1|    2797|   4.0|978302039|\n",
      "+-------+--------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, LongType, FloatType\n",
    "from pyspark.sql.functions import split, col\n",
    "file_location = home_dir+\"ratings.csv\"\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType(), nullable=False),\n",
    "    StructField(\"movie_id\", IntegerType(), nullable=False),\n",
    "    StructField(\"rating\", FloatType(), nullable=False),\n",
    "    StructField(\"timestamp\", LongType(), nullable=False)\n",
    "])\n",
    "\n",
    "df = spark.read \\\n",
    "    .option(\"sep\", \"::\") \\\n",
    "     .csv(file_location, schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78ad3d3",
   "metadata": {},
   "source": [
    "# 4.Import Data from URL: Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c90060a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/jhansiboda/anaconda3/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/jhansiboda/anaconda3/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jhansiboda/anaconda3/lib/python3.10/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/jhansiboda/anaconda3/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jhansiboda/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de2391f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1   2   3      4\n",
       "0  1  F   1  10  48067\n",
       "1  2  M  56  16  70072\n",
       "2  3  M  25  15  55117\n",
       "3  4  M  45   7  02460\n",
       "4  5  M  25  20  55455"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url =  home_dir+\"users.csv\"\n",
    "df = pd.read_csv(url, sep=\"::\", engine=\"python\", header=None)\n",
    "df.head()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d5c128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType(), nullable=True),\n",
    "    StructField(\"gender\", StringType(), nullable=True),\n",
    "    StructField(\"age\", IntegerType(), nullable=True),\n",
    "     StructField(\"occupation\", IntegerType(), nullable=True),\n",
    "    StructField(\"zip_code\", StringType(), nullable=True)\n",
    "])\n",
    "spark_df = spark.createDataFrame(df, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb71cf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---+----------+--------+\n",
      "|user_id|gender|age|occupation|zip_code|\n",
      "+-------+------+---+----------+--------+\n",
      "|      1|     F|  1|        10|   48067|\n",
      "|      2|     M| 56|        16|   70072|\n",
      "|      3|     M| 25|        15|   55117|\n",
      "|      4|     M| 45|         7|   02460|\n",
      "|      5|     M| 25|        20|   55455|\n",
      "|      6|     F| 50|         9|   55117|\n",
      "|      7|     M| 35|         1|   06810|\n",
      "|      8|     M| 25|        12|   11413|\n",
      "|      9|     M| 25|        17|   61614|\n",
      "|     10|     F| 35|         1|   95370|\n",
      "|     11|     F| 25|         1|   04093|\n",
      "|     12|     M| 25|        12|   32793|\n",
      "|     13|     M| 45|         1|   93304|\n",
      "|     14|     M| 35|         0|   60126|\n",
      "|     15|     M| 25|         7|   22903|\n",
      "|     16|     F| 35|         0|   20670|\n",
      "|     17|     M| 50|         1|   95350|\n",
      "|     18|     F| 18|         3|   95825|\n",
      "|     19|     M|  1|        10|   48073|\n",
      "|     20|     M| 25|        14|   55113|\n",
      "+-------+------+---+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04143dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- occupation: integer (nullable = true)\n",
      " |-- zip_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f33ecf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- occupation: integer (nullable = true)\n",
      " |-- zip_code: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "spark_df.withColumn('zip_code', col('zip_code').cast('int'))\n",
    "\n",
    "spark_df = spark_df.withColumn('zip_code', col('zip_code').cast('int'))\n",
    "\n",
    "spark_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754ada4b",
   "metadata": {},
   "source": [
    "# 5.Save table without defining DDL in Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "faea745b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/21 09:32:34 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---+----------+--------+\n",
      "|user_id|gender|age|occupation|zip_code|\n",
      "+-------+------+---+----------+--------+\n",
      "|   3776|     F| 25|         4|   50265|\n",
      "|   3777|     M| 18|         4|   23112|\n",
      "|   3778|     M| 25|         0|   61832|\n",
      "|   3779|     F| 45|         2|   98383|\n",
      "|   3780|     M|  1|         0|   46979|\n",
      "|   3781|     F| 56|        11|   54401|\n",
      "|   3782|     F| 25|         0|   94602|\n",
      "|   3783|     M| 25|         7|   97267|\n",
      "|   3784|     F| 25|         1|   98027|\n",
      "|   3785|     F| 25|        20|   93401|\n",
      "|   3786|     F| 25|         0|   94115|\n",
      "|   3787|     F| 25|         0|   94703|\n",
      "|   3788|     F| 18|         0|   94587|\n",
      "|   3789|     F| 25|         0|   94110|\n",
      "|   3790|     F| 25|        17|   94618|\n",
      "|   3791|     M| 50|        18|   60516|\n",
      "|   3792|     M| 25|         6|   68108|\n",
      "|   3793|     M| 18|         4|   21093|\n",
      "|   3794|     F| 18|         4|   53211|\n",
      "|   3795|     F| 18|         4|   91405|\n",
      "+-------+------+---+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.write.mode(\"overwrite\").saveAsTable('name')\n",
    "spark.sql(\"select * from name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "509c04a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|  default|     name|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e63a4f8",
   "metadata": {},
   "source": [
    "# 6.Broadcast Variable example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39ff8ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by normal join operation: 0.018440961837768555 seconds\n",
      "Time taken by broadcast join operation: 0.009475946426391602 seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import broadcast\n",
    "import time\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Create two sample DataFrames :df_ratings = home_dir+\"ratings.csv\"\n",
    "df_ratings = df_ratings\n",
    "\n",
    "column_rating = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    "df_rating = movies.toDF(*column_rating)\n",
    "\n",
    "column_names = [\"movie_id\",\"title\",\"genres\"]\n",
    "df_movie = df_movie.toDF(*column_names)\n",
    "\n",
    "# Defining broadcast dataframe\n",
    "broadcast_movie_df = broadcast(df_movie)\n",
    "\n",
    "# Capture the start timestamp\n",
    "start_time_normal_df = time.time()\n",
    "\n",
    "# Perform full join on the 'movie_id' column\n",
    "df_full_join = df_rating.join(df_movie, on = \"movie_id\", how = \"full\")\n",
    "\n",
    "# Capture the end timestamp\n",
    "end_time_normal_df = time.time()\n",
    "\n",
    "# Capture start time\n",
    "start_time_broadcast_df = time.time()\n",
    "\n",
    "#Perform full join on broadcast df\n",
    "sd_broadcast_full_join  = df_rating.join(broadcast_movie_df, on = \"movie_id\", how = \"full\")\n",
    "\n",
    "# Capture the end timestamp\n",
    "end_time_broadcast_df = time.time()\n",
    "\n",
    "# Calculate the time taken\n",
    "\n",
    "time_taken_normal = end_time_normal_df - start_time_normal_df\n",
    "time_taken_broadcast = end_time_broadcast_df - start_time_broadcast_df\n",
    "\n",
    "# Show the result\n",
    "#df_full_join.show()\n",
    "\n",
    "# Print the time taken\n",
    "print(f\"Time taken by normal join operation: {time_taken_normal} seconds\")\n",
    "\n",
    "print(f\"Time taken by broadcast join operation: {time_taken_broadcast} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20102e3c",
   "metadata": {},
   "source": [
    "# 7.Accumulator example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8109c9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+------+----+\n",
      "|movie_id|               title|genres|year|\n",
      "+--------+--------------------+------+----+\n",
      "|    3231| Saphead, The (1920)|Comedy|1920|\n",
      "|    3309|Dog's Life, A (1920)|Comedy|1920|\n",
      "+--------+--------------------+------+----+\n",
      "\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "column_names = [\"movie_id\",\"title\",\"genres\"]\n",
    "df_movie = df_movie.toDF(*column_names)\n",
    "\n",
    "# Create an accumulator for counting\n",
    "count_accumulator = spark.sparkContext.accumulator(0)\n",
    "\n",
    "# Find number of movies released between year 1920 to 1930\n",
    "\n",
    "df_movie_with_year = df_movie.withColumn(\"year\", substring('title', -5, 4).cast(\"int\"))\n",
    "\n",
    "df_movie_with_year.filter(col(\"year\")== 1920).show()\n",
    "df_movie_with_year.foreach(lambda row: count_accumulator.add(1) if row.year == 1920 else None)\n",
    "\n",
    "v = count_accumulator.value\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ac6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
