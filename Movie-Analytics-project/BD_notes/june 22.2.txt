from pyspark.sql import *
from pyspark.sql.functions import *
spark=SparkSession.builder.master("local[*]").appName("test").config("spark.sql.session.timeZone", "IST").getOrCreate()
#spark.conf.set("spark.sql.session.timeZone", "IST")


data ="D:\\Bigdata\\drivers\\donations.csv"
df1 = spark.read.format("csv").option("header","true").option("inferSchema","true").load(data)
df=df1.withColumn("dt",to_date(col("dt"),"d-M-yyyy")).withColumn("today",current_date())\
    .withColumn("datediff",datediff(col("today"),col("dt")))\
    .withColumn("datediffyymmdd",col("today")-col("dt"))\
    .withColumn("ts",current_timestamp()).withColumn("lastdt",last_day(col("dt")))\
    .withColumn("add",date_add(col("dt"),100)).withColumn("sub",date_add(col("dt"),-100))\
    .withColumn("addmon",add_months(col("today"),10))\
    .withColumn("dtformat",date_format(col("dt"),"yyyy/MMMM/dd/EEE/z/D"))\
    .withColumn("nextday",next_day(col("dt"),"Friday"))



df.show(truncate=False)
df.printSchema()
#https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html
#892
#by default spark understand 'yyyy-MM-dd' format only ... thsts y based on input data  u have to mention within to_date( format)